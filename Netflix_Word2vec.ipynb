{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Netflix_Word2vec.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlrTE0Cal06e"
      },
      "source": [
        "# <font color='#f78fb3'> Netflix Recommendations System - Word2Vec  |<br> </font>  \n",
        "# <font color='#3dc1d3'>  \n",
        "1.  Preprocess data\n",
        "2.  Transfer Learning, using Google Pretrained Data\n",
        "3.  Create Word2Vec Model\n",
        "4.  Content based Recommendation System; Find 'what to watch' based which you movie you watched <br>\n",
        "\n",
        "## <font color='#f9ca24'> Word Embedding\n",
        " <font color='00BFEB'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc3e06qZDflB"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import re\n",
        "import string\n",
        "import random\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "!pip install gensim #Install gensim, a useful NLP library that we will use to load w2v embeddings\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from matplotlib import pyplot\n",
        "from gensim.models import KeyedVectors\n",
        "import warnings  \n",
        "warnings.filterwarnings(action='ignore',category=UserWarning,module='gensim')  \n",
        "warnings.filterwarnings(action='ignore',category=FutureWarning,module='gensim')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7kENFKFhQoD"
      },
      "source": [
        "<font color='#f78fb3'>Load data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjmew0PhHwJ3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8DNpezeHwXX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zfT06-zITN5"
      },
      "source": [
        "### <font color='#f78fb3'>Explore dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XQPRIMcH-ih"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5_V9k2trns9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5bFOj6BRN8c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKllB0TwPtmH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3S1UWLYuSVF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dry8f3zJG0vt"
      },
      "source": [
        "### <font color='#f78fb3'>only show columns of interest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFi2MSIfIU0E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkW0hCl5vBfo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_4SfFDnqRZS"
      },
      "source": [
        "### <font color='#f78fb3'>drop null values in description column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB8mn1YBnSD-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slOsQcXLyJTo"
      },
      "source": [
        "### <font color='#f78fb3'>Visualize the length of descriptions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGW8opKDiHUa"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqfy6u93lz5N"
      },
      "source": [
        "<font color='#3dc1d3'> Ensure Descriptions only contain strings; not float dtyp; Pandas astype() is the one of the most important methods. It is used to change data type of a series. When data frame is made from a csv file, the columns are imported and data type is set automatically which many times is not what it actually should have. For example, a salary column could be imported as string but to do operations we have to convert it into float. In this case, the series in description column; the dtype needs to be converted to string, ensure it is not float\n",
        "astype() is used to do such data type conversions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE8HlDWpNe1z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUVePvpJHpJd"
      },
      "source": [
        " ### <font color='#f9ca24'> Preprocessing (cleaning) the Descriptions. <br>\n",
        " <font color='#3dc1d3'> Non-ASCII characters: भारत hindi;\n",
        ".网络 Chinese; Hebrew\n",
        ".קום, Arabic <br> Ascii - english based letters/digits/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZyYy5yZJOtm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfkcQmEH21hT"
      },
      "source": [
        " <font color='#3dc1d3'>A new column is created to store the cleaned, preprocessed descriptions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOOpZavd25Pj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9xYIooCOH0x"
      },
      "source": [
        "<font color='#f9ca24'>Start Work on the Word2Vec Model<br><font color='#f78fb3'>Splitting the descriptions into words and stored in a list called ‘universe’; universe is essentially our corpus used for training our word2vec model<br>The word2vec tool takes a text corpus as input and produces the word vectors as output. It first constructs a vocabulary from the training text data and then learns vector representation of words. The resulting word vector file can be used as features in many natural language processing and machine learning applications.<br><font color='#f78fb3'>Word tokenization; break up description into word chunks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6HhqiSRsHFi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EMUEQV82nyH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQOUn8_4s0HW"
      },
      "source": [
        "<font color='#f9ca24'>Transfer Learning<br><font color='#f78fb3'>using the word2vec pre-trained Google News model (GoogleNews-vectors-negative300) with the gensim Python library.<br>get GoogleNews pretrained data<br> takes a few seconds to load in gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIe70-i-Nu65"
      },
      "source": [
        "!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3dKlCXK3rme"
      },
      "source": [
        "<font color='#f78fb3'>embedding_file as the GoogleNews-vectors-negative300 file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HG4qLuDNvCC"
      },
      "source": [
        "EMBEDDING_FILE = '/root/input/GoogleNews-vectors-negative300.bin.gz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is5SZ9x9DNkK"
      },
      "source": [
        "<font color='#f78fb3'>Training corpus with Google Pretrained Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI4raOMHr-zL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BBxgzLnGxnB"
      },
      "source": [
        "<font color='#f78fb3'>Above: intersect_word2vec_format() <br>Merge the input-hidden weight matrix from the original word2vec format given, where it intersects with the current vocabulary/universe corpus. (What you need to note here: No words are added to the existing vocabulary, but intersecting words adopt the file’s weights, and non-intersecting words are left alone.)<br>binary is a boolean indicating whether the data is in binary word2vec format.<br>lockf is a lock-factor value to be set for any imported word-vectors; the default value of 0.0 prevents further updating of the vector during subsequent training. Use 1.0 to allow further training updates of merged vectors.<br>\n",
        "<br>\n",
        "The parameters:\n",
        "min_count =  Ignores all words with total absolute frequency lower than this - (2, 100)<br>\n",
        "window = The maximum distance between the current and predicted word within a sentence. E.g. window words on the left and window words on the left of our target - (2, 10)<br>\n",
        "size = int - Dimensionality of the feature vectors. - (50, 300)<br>\n",
        "sample = float - The threshold for configuring which higher-frequency words are randomly downsampled. Highly influencial. - (0, 1e-5) <br> \n",
        "workers = int - Use these many worker threads to train the model (=faster training with multicore machines)<br>\n",
        "Word2Vec needs a vocabulary; (taking in the tokens and filtering out the unique ones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDOvwAPRetHp"
      },
      "source": [
        "<font color='#3dc1d3'>Try out the similarity between words; after intersecting with our corpus-universe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46512qtOXMeJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YSMJuAzXi9R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgJUywyMXa6D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnteSNRCaZTq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaSS1LSrZMOT"
      },
      "source": [
        "<font color='#f78fb3'>The function Vectorize() defines the average word2vec for each Netflix description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vm69CqdZMYq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb6q5ireJnHE"
      },
      "source": [
        "<font color='#f78fb3'>define the function to find the top 5 most similar/recommended Netflix shows, based on the one you previously watched.<br>Invert index; we have a dictionary of characters/embeddings from Description mapped to their titles, and we want to convert that to a dictionary of titles mapped to the characters that have them.<br> We trained on the descriptions of the Netflix shows but we want to search/match based on a title. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ3Yvt6wZU8n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OqdX_4cJ68Q"
      },
      "source": [
        "<font color='#f9ca24'> Netflix Recommendations "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdM8xACAZdL0"
      },
      "source": [
        "netflix_because_you_watched(\"Transformers Prime\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzERNAAseuTI"
      },
      "source": [
        "netflix_because_you_watched(\"Friends\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aNH46W-gQI_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkOrZsYORKy5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}